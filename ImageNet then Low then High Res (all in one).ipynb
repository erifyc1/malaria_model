{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:\\\\.Downloads\\\\low_res\\\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d6371776dcf8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     validation_split=0.2)\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m lr_train_generator = lr_train_datagen.flow_from_directory(\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[1;34m'D:\\.Downloads\\low_res\\data'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#'/content/drive/My Drive/malariaNN/high_res/data',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[0;32m    940\u001b[0m             \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m     \"\"\"\n\u001b[1;32m--> 942\u001b[1;33m     return DirectoryIterator(\n\u001b[0m\u001b[0;32m    943\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dtype'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m     super(DirectoryIterator, self).__init__(\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_data_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'D:\\\\.Downloads\\\\low_res\\\\data'"
     ]
    }
   ],
   "source": [
    "#get and split low_res data\n",
    "height = 299\n",
    "width = 299\n",
    "lr_batch_size = 4\n",
    "\n",
    "lr_train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "lr_train_generator = lr_train_datagen.flow_from_directory(\n",
    "    'D:\\.Downloads\\low_res\\data',#'/content/drive/My Drive/malariaNN/high_res/data', C:\\Users\\stolk\\Desktop\\Workspaces\\ML\\malaria\\high_res\\data\n",
    "    target_size=(height, width),\n",
    "    batch_size=lr_batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training')\n",
    "lr_validation_generator = lr_train_datagen.flow_from_directory(\n",
    "    'D:\\.Downloads\\low_res\\data',#'/content/drive/My Drive/malariaNN/high_res/data',\n",
    "    target_size=(height, width),\n",
    "    batch_size=lr_batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation')\n",
    "\n",
    "lr_epochs = 15\n",
    "lr_steps = 22048\n",
    "lr_val_steps = 5510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build inceptionv3 algorithm and compile\n",
    "input_shape = None\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, width, height)\n",
    "else:\n",
    "    input_shape = (width, height, 3)\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=Input(shape=input_shape))\n",
    "\n",
    "out = base_model.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(1024, activation='relu')(out)\n",
    "predictions = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "LR = 0.0001\n",
    "RMS = Adam(lr=LR)\n",
    "model.compile(optimizer=RMS, loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "5512/5512 [==============================] - 525s 95ms/step - loss: 0.1621 - accuracy: 0.9509 - val_loss: 0.1913 - val_accuracy: 0.9437\n",
      "Epoch 2/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.1325 - accuracy: 0.9590 - val_loss: 0.1946 - val_accuracy: 0.9261\n",
      "Epoch 3/15\n",
      "5512/5512 [==============================] - 509s 92ms/step - loss: 0.1165 - accuracy: 0.9625 - val_loss: 0.1258 - val_accuracy: 0.9564\n",
      "Epoch 4/15\n",
      "5512/5512 [==============================] - 509s 92ms/step - loss: 0.1094 - accuracy: 0.9655 - val_loss: 0.1407 - val_accuracy: 0.9530\n",
      "Epoch 5/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.1045 - accuracy: 0.9661 - val_loss: 0.1914 - val_accuracy: 0.9321\n",
      "Epoch 6/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.0977 - accuracy: 0.9693 - val_loss: 0.1322 - val_accuracy: 0.9532\n",
      "Epoch 7/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.0918 - accuracy: 0.9693 - val_loss: 0.1435 - val_accuracy: 0.9513\n",
      "Epoch 8/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.0866 - accuracy: 0.9698 - val_loss: 0.1338 - val_accuracy: 0.9521\n",
      "Epoch 9/15\n",
      "5512/5512 [==============================] - 509s 92ms/step - loss: 0.0846 - accuracy: 0.9707 - val_loss: 0.1380 - val_accuracy: 0.9559\n",
      "Epoch 10/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.0808 - accuracy: 0.9736 - val_loss: 0.1650 - val_accuracy: 0.9464\n",
      "Epoch 11/15\n",
      "5512/5512 [==============================] - 509s 92ms/step - loss: 0.0740 - accuracy: 0.9753 - val_loss: 0.1561 - val_accuracy: 0.9508\n",
      "Epoch 12/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.0725 - accuracy: 0.9746 - val_loss: 0.1386 - val_accuracy: 0.9539\n",
      "Epoch 13/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.0686 - accuracy: 0.9761 - val_loss: 0.1852 - val_accuracy: 0.9381\n",
      "Epoch 14/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.0670 - accuracy: 0.9763 - val_loss: 0.1949 - val_accuracy: 0.9370\n",
      "Epoch 15/15\n",
      "5512/5512 [==============================] - 508s 92ms/step - loss: 0.0630 - accuracy: 0.9790 - val_loss: 0.1363 - val_accuracy: 0.9546\n"
     ]
    }
   ],
   "source": [
    "#train to fit low_res data\n",
    "history = model.fit(\n",
    "    lr_train_generator,\n",
    "    epochs=lr_epochs,\n",
    "    steps_per_epoch=lr_steps // lr_batch_size,\n",
    "    validation_data=lr_validation_generator,\n",
    "    validation_steps=lr_val_steps // lr_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = 'D:\\.Downloads\\models\\\\allinone\\modelweights.h5'\n",
    "base_model.save_weights(model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 210 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#get and split high_res data\n",
    "hr_batch_size = 1\n",
    "\n",
    "hr_train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "hr_train_generator = hr_train_datagen.flow_from_directory(\n",
    "    'D:\\.Downloads\\high_res\\data',#'/content/drive/My Drive/malariaNN/high_res/data',\n",
    "    target_size=(height, width),\n",
    "    batch_size=hr_batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "hr_validation_generator = hr_train_datagen.flow_from_directory(\n",
    "    'D:\\.Downloads\\high_res\\data',#'/content/drive/My Drive/malariaNN/high_res/data',\n",
    "    target_size=(height, width),\n",
    "    batch_size=hr_batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "hr_epochs = 10\n",
    "hr_steps = 170\n",
    "hr_val_steps = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build inceptionv3 algorithm and compile\n",
    "input_shape = None\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, width, height)\n",
    "else:\n",
    "    input_shape = (width, height, 3)\n",
    "\n",
    "final_base_model = InceptionV3(weights=model_location, include_top=False, input_tensor=Input(shape=input_shape))\n",
    "\n",
    "out = final_base_model.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(1024, activation='relu')(out)\n",
    "predictions = Dense(4, activation='softmax')(out)\n",
    "\n",
    "final_model = Model(inputs=final_base_model.input, outputs=predictions)\n",
    "#freeze algorithm and set up for high_res\n",
    "#for layer in base_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "LR = 0.0001\n",
    "RMS = Adam(lr=LR)\n",
    "final_model.compile(optimizer=RMS, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'tensorflow.python.keras.preprocessing.image.DirectoryIterator'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-47a4e4b1665f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#fit last 2 layers with high_res data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m final_history = final_model.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mhr_train_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhr_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1037\u001b[0m       \u001b[1;31m# `Tensor` and `NumPy` input.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m       (x, y, sample_weight), validation_data = (\n\u001b[1;32m-> 1039\u001b[1;33m           data_adapter.train_validation_split(\n\u001b[0m\u001b[0;32m   1040\u001b[0m               (x, y, sample_weight), validation_split=validation_split))\n\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mtrain_validation_split\u001b[1;34m(arrays, validation_split)\u001b[0m\n\u001b[0;32m   1372\u001b[0m   \u001b[0munsplitable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mflat_arrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_can_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0munsplitable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m   1375\u001b[0m         \u001b[1;34m\"`validation_split` is only supported for Tensors or NumPy \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \"arrays, found following types in the input: {}\".format(unsplitable))\n",
      "\u001b[1;31mValueError\u001b[0m: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class 'tensorflow.python.keras.preprocessing.image.DirectoryIterator'>]"
     ]
    }
   ],
   "source": [
    "#fit last 2 layers with high_res data\n",
    "final_history = final_model.fit(\n",
    "    hr_train_generator,\n",
    "    epochs=hr_epochs,\n",
    "    steps_per_epoch=hr_steps // hr_batch_size,\n",
    "    validation_data=hr_validation_generator,\n",
    "    validation_steps=hr_val_steps // hr_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 3s 79ms/step - loss: 4.4486 - accuracy: 0.1500\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 4.4898 - accuracy: 0.1500\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 4.6553 - accuracy: 0.1750\n",
      "40/40 [==============================] - 3s 78ms/step - loss: 4.7293 - accuracy: 0.1750\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 4.7322 - accuracy: 0.1500\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 4.4687 - accuracy: 0.1500\n",
      "40/40 [==============================] - ETA: 0s - loss: 4.5430 - accuracy: 0.15 - 3s 79ms/step - loss: 4.5494 - accuracy: 0.1500\n",
      "40/40 [==============================] - 3s 80ms/step - loss: 4.5283 - accuracy: 0.1500 1s - l\n",
      "40/40 [==============================] - 3s 77ms/step - loss: 4.7350 - accuracy: 0.1500\n",
      "40/40 [==============================] - 3s 79ms/step - loss: 4.7543 - accuracy: 0.1500\n",
      "Avg accuracy: 0.15500000417232512\n"
     ]
    }
   ],
   "source": [
    "#check accuracy\n",
    "accs = 0\n",
    "for i in range(10):\n",
    "    accuracy = final_model.evaluate(\n",
    "        hr_validation_generator,\n",
    "        steps=hr_val_steps // hr_batch_size,\n",
    "    )\n",
    "    accs += accuracy[1]\n",
    "print(\"Avg accuracy: \" + str(accs/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
