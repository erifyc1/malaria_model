{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all libraries\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, Input, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22048 images belonging to 2 classes.\n",
      "Found 5510 images belonging to 2 classes.\n",
      "22048\n",
      "5510\n"
     ]
    }
   ],
   "source": [
    "#get and split low_res data\n",
    "height = 299\n",
    "width = 299\n",
    "lr_batch_size = 4\n",
    "\n",
    "lr_train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "lr_train_generator = lr_train_datagen.flow_from_directory(\n",
    "    'C:/Users/stolk/Desktop/Workspaces/ML/malaria/low_res/data',#'/content/drive/My Drive/malariaNN/high_res/data',\n",
    "    target_size=(height, width),\n",
    "    batch_size=lr_batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training')\n",
    "lr_validation_generator = lr_train_datagen.flow_from_directory(\n",
    "    'C:/Users/stolk/Desktop/Workspaces/ML/malaria/low_res/data',#'/content/drive/My Drive/malariaNN/high_res/data',\n",
    "    target_size=(height, width),\n",
    "    batch_size=lr_batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation')\n",
    "\n",
    "lr_epochs = 1\n",
    "lr_steps = 22048 // 1\n",
    "lr_val_steps = 5510 // 1\n",
    "\n",
    "print(lr_steps)\n",
    "print(lr_val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build inceptionv3 algorithm and compile\n",
    "input_shape = None\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, width, height)\n",
    "else:\n",
    "    input_shape = (width, height, 3)\n",
    "\n",
    "base_model = InceptionV3(weights=None, include_top=False, input_tensor=Input(shape=input_shape))\n",
    "\n",
    "out = base_model.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(1024, activation='relu')(out)\n",
    "predictions = Dense(1, activation='sigmoid')(out)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "LR = 0.0001\n",
    "RMS = Adam(lr=LR)\n",
    "model.compile(optimizer=RMS, loss='binary_crossentropy', metrics=['accuracy',f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5512/5512 [==============================] - 556s 99ms/step - loss: 0.3560 - accuracy: 0.8432 - f1_m: 0.7846 - precision_m: 0.7954 - recall_m: 0.8153 - val_loss: 0.1643 - val_accuracy: 0.9424 - val_f1_m: 0.8642 - val_precision_m: 0.8848 - val_recall_m: 0.8637\n"
     ]
    }
   ],
   "source": [
    "#train to fit low_res data\n",
    "history = model.fit(\n",
    "    lr_train_generator,\n",
    "    epochs=lr_epochs,\n",
    "    steps_per_epoch=lr_steps // lr_batch_size,\n",
    "    validation_data=lr_validation_generator,\n",
    "    validation_steps=lr_val_steps // lr_batch_size\n",
    ")\n",
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377/1377 [==============================] - 41s 29ms/step - loss: 0.1633 - accuracy: 0.9439 - f1_m: 0.8759 - precision_m: 0.8946 - recall_m: 0.8765\n",
      "loss: 0.16329272091388702\n",
      "acc: 0.9438998103141785\n",
      "f1: 0.8759000301361084\n",
      "pre: 0.8946380019187927\n",
      "rec: 0.8765432238578796\n"
     ]
    }
   ],
   "source": [
    "#check accuracy\n",
    "results = model.evaluate(\n",
    "    lr_validation_generator,\n",
    "    steps=lr_val_steps // lr_batch_size,\n",
    ")\n",
    "\n",
    "print(\"loss: \" + str(results[0]))\n",
    "print(\"acc: \" + str(results[1]))\n",
    "print(\"f1: \" + str(results[2]))\n",
    "print(\"pre: \" + str(results[3]))\n",
    "print(\"rec: \" + str(results[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full none\n",
    "# \n",
    "# acc: 0.9438998103141785\n",
    "# f1: 0.8759000301361084\n",
    "# pre: 0.8946380019187927\n",
    "# rec: 0.8765432238578796\n",
    "\n",
    "# full img\n",
    "# \n",
    "# acc: 0.9509803652763367\n",
    "# f1: 0.8894315361976624\n",
    "# pre: 0.8993586301803589\n",
    "# rec: 0.8959693908691406\n",
    "\n",
    "# 1/2 none\n",
    "# acc: 0.9411337375640869\n",
    "# f1: 0.882910430431366\n",
    "# pre: 0.8679748177528381\n",
    "# rec: 0.918483555316925\n",
    "\n",
    "# 1/2 img\n",
    "# acc: 0.9571220874786377\n",
    "# f1: 0.9032805562019348\n",
    "# pre: 0.9016472697257996\n",
    "# rec: 0.9204215407371521\n",
    "\n",
    "# 1/4 none\n",
    "#\n",
    "# acc: 0.9004360437393188\n",
    "# f1: 0.8495294451713562\n",
    "# pre: 0.8192830681800842\n",
    "# rec: 0.9140018820762634\n",
    "\n",
    "# 1/4 img\n",
    "#\n",
    "# acc: 0.9549418687820435\n",
    "# f1: 0.8903377652168274\n",
    "# pre: 0.8943797945976257\n",
    "# rec: 0.9011628031730652\n",
    "\n",
    "# 1/8 none\n",
    "# \n",
    "# acc: 0.694767415523529\n",
    "# f1: 0.47411394119262695\n",
    "# pre: 0.6143410801887512\n",
    "# rec: 0.413759708404541\n",
    "\n",
    "# 1/8 img\n",
    "# \n",
    "# acc: 0.9534883499145508\n",
    "# f1: 0.8955152034759521\n",
    "# pre: 0.9040697813034058\n",
    "# rec: 0.9040697813034058\n",
    "\n",
    "# 1/16 none\n",
    "# \n",
    "# acc: 0.5174418687820435\n",
    "# f1: 0.64418625831604\n",
    "# pre: 0.5174418687820435\n",
    "# rec: 0.9534883499145508\n",
    "\n",
    "# 1/16 img\n",
    "# \n",
    "# acc: 0.9186046719551086\n",
    "# f1: 0.8664452433586121\n",
    "# pre: 0.9089148044586182\n",
    "# rec: 0.846899151802063\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = 'D:\\.Downloads\\models\\\\allinone\\modelweights.h5'\n",
    "base_model.save_weights(model_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
