{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model,Sequential\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 12435211327219962545\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7017170208\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9987303805570526535\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 170 images belonging to 4 classes.\n",
      "Found 40 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "height = 299\n",
    "width = 299\n",
    "batch_size = 4\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=False,\n",
    "    validation_split=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/stolk/Desktop/Workspaces/ML/malaria/high_res/data',#'/content/drive/My Drive/malariaNN/high_res/data',\n",
    "    target_size=(height, width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'C:/Users/stolk/Desktop/Workspaces/ML/malaria/high_res/data',#'/content/drive/My Drive/malariaNN/high_res/data',\n",
    "    target_size=(height, width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n",
    "\n",
    "epochs = 20\n",
    "steps = 170\n",
    "val_steps = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "out = base_model.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "# fully-connected layer\n",
    "out = Dense(1024, activation='relu')(out)\n",
    "predictions = Dense(4, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# freeze all weights in imagenet trained base model, but not the extra buffer layer and output layer\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "    \n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "    \n",
    "\n",
    "LR = 0.007\n",
    "RMS = Adam(lr=LR)\n",
    "model.compile(optimizer=RMS, loss='categorical_crossentropy', metrics=['accuracy',f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42/42 [==============================] - 19s 341ms/step - loss: 9.8897 - accuracy: 0.4984 - f1_m: 0.4404 - precision_m: 0.4479 - recall_m: 0.4347 - val_loss: 1.5026 - val_accuracy: 0.6500 - val_f1_m: 0.6500 - val_precision_m: 0.6500 - val_recall_m: 0.6500\n",
      "Epoch 2/20\n",
      "42/42 [==============================] - 13s 303ms/step - loss: 1.1446 - accuracy: 0.6942 - f1_m: 0.6938 - precision_m: 0.6942 - recall_m: 0.6935 - val_loss: 1.2311 - val_accuracy: 0.5000 - val_f1_m: 0.5036 - val_precision_m: 0.5083 - val_recall_m: 0.5000\n",
      "Epoch 3/20\n",
      "42/42 [==============================] - 13s 301ms/step - loss: 0.4578 - accuracy: 0.8470 - f1_m: 0.8454 - precision_m: 0.8521 - recall_m: 0.8404 - val_loss: 0.6635 - val_accuracy: 0.6500 - val_f1_m: 0.6583 - val_precision_m: 0.7083 - val_recall_m: 0.6250\n",
      "Epoch 4/20\n",
      "42/42 [==============================] - 13s 303ms/step - loss: 0.3886 - accuracy: 0.8352 - f1_m: 0.8581 - precision_m: 0.9005 - recall_m: 0.8264 - val_loss: 0.7776 - val_accuracy: 0.7500 - val_f1_m: 0.7571 - val_precision_m: 0.7667 - val_recall_m: 0.7500\n",
      "Epoch 5/20\n",
      "42/42 [==============================] - 13s 299ms/step - loss: 0.5665 - accuracy: 0.8389 - f1_m: 0.8322 - precision_m: 0.8403 - recall_m: 0.8270 - val_loss: 0.6056 - val_accuracy: 0.6250 - val_f1_m: 0.6643 - val_precision_m: 0.7167 - val_recall_m: 0.6250\n",
      "Epoch 6/20\n",
      "42/42 [==============================] - 12s 295ms/step - loss: 0.3931 - accuracy: 0.8380 - f1_m: 0.8216 - precision_m: 0.8292 - recall_m: 0.8160 - val_loss: 0.8926 - val_accuracy: 0.6750 - val_f1_m: 0.6750 - val_precision_m: 0.6750 - val_recall_m: 0.6750\n",
      "Epoch 7/20\n",
      "42/42 [==============================] - 13s 311ms/step - loss: 0.4184 - accuracy: 0.8290 - f1_m: 0.8027 - precision_m: 0.8153 - recall_m: 0.7939 - val_loss: 0.6539 - val_accuracy: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
      "Epoch 8/20\n",
      "42/42 [==============================] - 13s 304ms/step - loss: 0.3697 - accuracy: 0.8337 - f1_m: 0.8274 - precision_m: 0.8333 - recall_m: 0.8230 - val_loss: 0.4960 - val_accuracy: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
      "Epoch 9/20\n",
      "42/42 [==============================] - 12s 297ms/step - loss: 0.2341 - accuracy: 0.9177 - f1_m: 0.9141 - precision_m: 0.9181 - recall_m: 0.9112 - val_loss: 0.5091 - val_accuracy: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
      "Epoch 10/20\n",
      "42/42 [==============================] - 12s 295ms/step - loss: 0.2522 - accuracy: 0.8902 - f1_m: 0.8856 - precision_m: 0.8890 - recall_m: 0.8831 - val_loss: 0.5118 - val_accuracy: 0.7500 - val_f1_m: 0.7607 - val_precision_m: 0.7750 - val_recall_m: 0.7500\n",
      "Epoch 11/20\n",
      "42/42 [==============================] - 13s 299ms/step - loss: 0.2761 - accuracy: 0.8763 - f1_m: 0.8766 - precision_m: 0.8766 - recall_m: 0.8766 - val_loss: 0.7986 - val_accuracy: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
      "Epoch 12/20\n",
      "42/42 [==============================] - 12s 296ms/step - loss: 0.3040 - accuracy: 0.8608 - f1_m: 0.8571 - precision_m: 0.8639 - recall_m: 0.8520 - val_loss: 0.5881 - val_accuracy: 0.7000 - val_f1_m: 0.7107 - val_precision_m: 0.7250 - val_recall_m: 0.7000\n",
      "Epoch 13/20\n",
      "42/42 [==============================] - 13s 300ms/step - loss: 0.1812 - accuracy: 0.9354 - f1_m: 0.9158 - precision_m: 0.9367 - recall_m: 0.9002 - val_loss: 0.3498 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 14/20\n",
      "42/42 [==============================] - 13s 302ms/step - loss: 0.1588 - accuracy: 0.9230 - f1_m: 0.9224 - precision_m: 0.9224 - recall_m: 0.9224 - val_loss: 0.5480 - val_accuracy: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 15/20\n",
      "42/42 [==============================] - 13s 307ms/step - loss: 0.2256 - accuracy: 0.9124 - f1_m: 0.9124 - precision_m: 0.9155 - recall_m: 0.9101 - val_loss: 0.5840 - val_accuracy: 0.8000 - val_f1_m: 0.7857 - val_precision_m: 0.8000 - val_recall_m: 0.7750\n",
      "Epoch 16/20\n",
      "42/42 [==============================] - 13s 302ms/step - loss: 0.6186 - accuracy: 0.8195 - f1_m: 0.8267 - precision_m: 0.8405 - recall_m: 0.8163 - val_loss: 0.9040 - val_accuracy: 0.8250 - val_f1_m: 0.8250 - val_precision_m: 0.8250 - val_recall_m: 0.8250\n",
      "Epoch 17/20\n",
      "42/42 [==============================] - 13s 308ms/step - loss: 0.1756 - accuracy: 0.9371 - f1_m: 0.9370 - precision_m: 0.9374 - recall_m: 0.9367 - val_loss: 1.3672 - val_accuracy: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n",
      "Epoch 18/20\n",
      "42/42 [==============================] - 12s 296ms/step - loss: 0.6137 - accuracy: 0.8146 - f1_m: 0.8188 - precision_m: 0.8236 - recall_m: 0.8152 - val_loss: 3.0127 - val_accuracy: 0.7250 - val_f1_m: 0.7250 - val_precision_m: 0.7250 - val_recall_m: 0.7250\n",
      "Epoch 19/20\n",
      "42/42 [==============================] - 13s 306ms/step - loss: 0.5219 - accuracy: 0.8647 - f1_m: 0.8680 - precision_m: 0.8680 - recall_m: 0.8680 - val_loss: 0.6217 - val_accuracy: 0.7500 - val_f1_m: 0.7500 - val_precision_m: 0.7500 - val_recall_m: 0.7500\n",
      "Epoch 20/20\n",
      "42/42 [==============================] - 13s 315ms/step - loss: 0.2802 - accuracy: 0.8834 - f1_m: 0.8921 - precision_m: 0.9034 - recall_m: 0.8836 - val_loss: 0.5316 - val_accuracy: 0.8000 - val_f1_m: 0.8000 - val_precision_m: 0.8000 - val_recall_m: 0.8000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 309ms/step - loss: 0.4357 - accuracy: 0.8000 - f1_m: 0.8214 - precision_m: 0.8500 - recall_m: 0.8000\n",
      "loss: 0.4357386529445648\n",
      "acc: 0.800000011920929\n",
      "f1: 0.8214284777641296\n",
      "pre: 0.8500000238418579\n",
      "rec: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(\n",
    "    validation_generator,\n",
    "    steps=val_steps // batch_size,\n",
    ")\n",
    "\n",
    "print(\"loss: \" + str(results[0]))\n",
    "print(\"acc: \" + str(results[1]))\n",
    "print(\"f1: \" + str(results[2]))\n",
    "print(\"pre: \" + str(results[3]))\n",
    "print(\"rec: \" + str(results[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
